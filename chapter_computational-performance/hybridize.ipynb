{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e08abd",
   "metadata": {},
   "source": [
    "The following additional libraries are needed to run this\n",
    "notebook. Note that running on Colab is experimental, please report a Github\n",
    "issue if you have any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40690ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054779e",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 编译器和解释器\n",
    ":label:`sec_hybridize`\n",
    "\n",
    "目前为止，本书主要关注的是*命令式编程*（imperative programming）。\n",
    "命令式编程使用诸如`print`、“`+`”和`if`之类的语句来更改程序的状态。\n",
    "考虑下面这段简单的命令式程序：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a91ac7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:38:07.302389Z",
     "iopub.status.busy": "2023-08-18T07:38:07.301672Z",
     "iopub.status.idle": "2023-08-18T07:38:07.313877Z",
     "shell.execute_reply": "2023-08-18T07:38:07.312741Z"
    },
    "origin_pos": 1,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def fancy_func(a, b, c, d):\n",
    "    e = add(a, b)\n",
    "    f = add(c, d)\n",
    "    g = add(e, f)\n",
    "    return g\n",
    "\n",
    "print(fancy_func(1, 2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3dbf9",
   "metadata": {
    "origin_pos": 2
   },
   "source": [
    "Python是一种*解释型语言*（interpreted language）。因此，当对上面的`fancy_func`函数求值时，它按顺序执行函数体的操作。也就是说，它将通过对`e = add(a, b)`求值，并将结果存储为变量`e`，从而更改程序的状态。接下来的两个语句`f = add(c, d)`和`g = add(e, f)`也将执行类似地操作，即执行加法计算并将结果存储为变量。 :numref:`fig_compute_graph`说明了数据流。\n",
    "\n",
    "![命令式编程中的数据流](http://d2l.ai/_images/computegraph.svg)\n",
    ":label:`fig_compute_graph`\n",
    "\n",
    "尽管命令式编程很方便，但可能效率不高。一方面原因，Python会单独执行这三个函数的调用，而没有考虑`add`函数在`fancy_func`中被重复调用。如果在一个GPU（甚至多个GPU）上执行这些命令，那么Python解释器产生的开销可能会非常大。此外，它需要保存`e`和`f`的变量值，直到`fancy_func`中的所有语句都执行完毕。这是因为程序不知道在执行语句`e = add(a, b)`和`f = add(c, d)`之后，其他部分是否会使用变量`e`和`f`。\n",
    "\n",
    "## 符号式编程\n",
    "\n",
    "考虑另一种选择*符号式编程*（symbolic programming），即代码通常只在完全定义了过程之后才执行计算。这个策略被多个深度学习框架使用，包括Theano和TensorFlow（后者已经获得了命令式编程的扩展）。一般包括以下步骤：\n",
    "\n",
    "1. 定义计算流程；\n",
    "1. 将流程编译成可执行的程序；\n",
    "1. 给定输入，调用编译好的程序执行。\n",
    "\n",
    "这将允许进行大量的优化。首先，在大多数情况下，我们可以跳过Python解释器。从而消除因为多个更快的GPU与单个CPU上的单个Python线程搭配使用时产生的性能瓶颈。其次，编译器可以将上述代码优化和重写为`print((1 + 2) + (3 + 4))`甚至`print(10)`。因为编译器在将其转换为机器指令之前可以看到完整的代码，所以这种优化是可以实现的。例如，只要某个变量不再需要，编译器就可以释放内存（或者从不分配内存），或者将代码转换为一个完全等价的片段。下面，我们将通过模拟命令式编程来进一步了解符号式编程的概念。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035798aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:38:07.318360Z",
     "iopub.status.busy": "2023-08-18T07:38:07.317707Z",
     "iopub.status.idle": "2023-08-18T07:38:07.325031Z",
     "shell.execute_reply": "2023-08-18T07:38:07.323819Z"
    },
    "origin_pos": 3,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "def fancy_func(a, b, c, d):\n",
      "    e = add(a, b)\n",
      "    f = add(c, d)\n",
      "    g = add(e, f)\n",
      "    return g\n",
      "print(fancy_func(1, 2, 3, 4))\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "def add_():\n",
    "    return '''\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "'''\n",
    "\n",
    "def fancy_func_():\n",
    "    return '''\n",
    "def fancy_func(a, b, c, d):\n",
    "    e = add(a, b)\n",
    "    f = add(c, d)\n",
    "    g = add(e, f)\n",
    "    return g\n",
    "'''\n",
    "\n",
    "def evoke_():\n",
    "    return add_() + fancy_func_() + 'print(fancy_func(1, 2, 3, 4))'\n",
    "\n",
    "prog = evoke_()\n",
    "print(prog)\n",
    "y = compile(prog, '', 'exec')\n",
    "exec(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077ceb8",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "命令式（解释型）编程和符号式编程的区别如下：\n",
    "\n",
    "* 命令式编程更容易使用。在Python中，命令式编程的大部分代码都是简单易懂的。命令式编程也更容易调试，这是因为无论是获取和打印所有的中间变量值，或者使用Python的内置调试工具都更加简单；\n",
    "* 符号式编程运行效率更高，更易于移植。符号式编程更容易在编译期间优化代码，同时还能够将程序移植到与Python无关的格式中，从而允许程序在非Python环境中运行，避免了任何潜在的与Python解释器相关的性能问题。\n",
    "\n",
    "## 混合式编程\n",
    "\n",
    "历史上，大部分深度学习框架都在命令式编程与符号式编程之间进行选择。例如，Theano、TensorFlow（灵感来自前者）、Keras和CNTK采用了符号式编程。相反地，Chainer和PyTorch采取了命令式编程。在后来的版本更新中，TensorFlow2.0和Keras增加了命令式编程。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e11595",
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "命令式编程现在是TensorFlow2的默认选择，对那些刚接触该语言的人来说是一个很好的改变。不过，符号式编程技术和计算图仍然存在于TensorFlow中，并且可以通过易于使用的装饰器`tf.function`进行访问。这为TensorFlow带来了命令式编程范式，允许用户定义更加直观的函数，然后使用被TensorFlow团队称为[autograph](https://www.tensorflow.org/api_docs/python/tf/autograph)的特性将它们封装，再自动编译成计算图。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0333d3d2",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "## `Sequential`的混合式编程\n",
    "\n",
    "要了解混合式编程的工作原理，最简单的方法是考虑具有多层的深层网络。按照惯例，Python解释器需要执行所有层的代码来生成一条指令，然后将该指令转发到CPU或GPU。对于单个的（快速的）计算设备，这不会导致任何重大问题。另一方面，如果我们使用先进的8-GPU服务器，比如AWS P3dn.24xlarge实例，Python将很难让所有的GPU都保持忙碌。在这里，瓶颈是单线程的Python解释器。让我们看看如何通过将`Sequential`替换为`HybridSequential`来解决代码中这个瓶颈。首先，我们定义一个简单的多层感知机。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06997e92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:38:07.329512Z",
     "iopub.status.busy": "2023-08-18T07:38:07.328833Z",
     "iopub.status.idle": "2023-08-18T07:38:13.762685Z",
     "shell.execute_reply": "2023-08-18T07:38:13.761763Z"
    },
    "origin_pos": 12,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0.9541333 , -0.74289465]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from d2l import tensorflow as d2l\n",
    "\n",
    "\n",
    "# 生产网络的工厂模式\n",
    "def get_net():\n",
    "    net = tf.keras.Sequential()\n",
    "    net.add(Dense(256, input_shape = (512,), activation = \"relu\"))\n",
    "    net.add(Dense(128, activation = \"relu\"))\n",
    "    net.add(Dense(2, activation = \"linear\"))\n",
    "    return net\n",
    "\n",
    "x = tf.random.normal([1,512])\n",
    "net = get_net()\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f697e851",
   "metadata": {
    "origin_pos": 16,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "一开始，TensorFlow中构建的所有函数都是作为计算图构建的，因此默认情况下是JIT编译的。但是，随着TensorFlow2.X和EargeTensor的发布，计算图就不再是默认行为。我们可以使用tf.function重新启用这个功能。tf.function更常被用作函数装饰器，如下所示，它也可以直接将其作为普通的Python函数调用。模型的计算结果保持不变。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb45cb6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:38:13.766735Z",
     "iopub.status.busy": "2023-08-18T07:38:13.766120Z",
     "iopub.status.idle": "2023-08-18T07:38:13.898046Z",
     "shell.execute_reply": "2023-08-18T07:38:13.897205Z"
    },
    "origin_pos": 20,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0.9541333 , -0.74289465]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.function(net)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb584ea3",
   "metadata": {
    "origin_pos": 24,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "我们编写与之前相同的代码，再使用`tf.function`简单地转换模型，当完成这些任务后，网络将以TensorFlow的MLIR中间表示形式构建为一个计算图，并在编译器级别进行大量优化以满足快速执行的需要（我们将在下面对性能进行基准测试）。通过将`jit_compile = True`标志添加到`tf.function()`的函数调用中可以显式地启用TensorFlow中的XLA（线性代数加速）功能。在某些情况下，XLA可以进一步优化JIT的编译代码。如果没有这种显式定义，图形模式将会被启用，但是XLA可以使某些大规模的线性代数的运算速度更快（与我们在深度学习程序中看到的操作类似），特别是在GPU环境中。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8408ef3",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "### 通过混合式编程加速\n",
    "\n",
    "为了证明通过编译获得了性能改进，我们比较了混合编程前后执行`net(x)`所需的时间。让我们先定义一个度量时间的类，它在本章中在衡量（和改进）模型性能时将非常有用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a54fd63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:38:13.902165Z",
     "iopub.status.busy": "2023-08-18T07:38:13.901606Z",
     "iopub.status.idle": "2023-08-18T07:38:13.906821Z",
     "shell.execute_reply": "2023-08-18T07:38:13.906038Z"
    },
    "origin_pos": 27,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class Benchmark:\n",
    "    \"\"\"用于测量运行时间\"\"\"\n",
    "    def __init__(self, description='Done'):\n",
    "        self.description = description\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.timer = d2l.Timer()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        print(f'{self.description}: {self.timer.stop():.4f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f23eb0",
   "metadata": {
    "origin_pos": 30,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "现在我们可以调用网络三次，一次使用eager模式，一次是使用图模式，一次使用JIT编译的XLA。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d80a9d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:38:13.910596Z",
     "iopub.status.busy": "2023-08-18T07:38:13.909902Z",
     "iopub.status.idle": "2023-08-18T07:38:15.802719Z",
     "shell.execute_reply": "2023-08-18T07:38:15.801807Z"
    },
    "origin_pos": 34,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager模式: 1.2769 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph模式: 0.5811 sec\n"
     ]
    }
   ],
   "source": [
    "net = get_net()\n",
    "with Benchmark('Eager模式'):\n",
    "    for i in range(1000): net(x)\n",
    "\n",
    "net = tf.function(net)\n",
    "with Benchmark('Graph模式'):\n",
    "    for i in range(1000): net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06900dcb",
   "metadata": {
    "origin_pos": 38,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "如以上结果所示，在`tf.keras.Sequential`的实例被函数`tf.function`脚本化后，通过使用TensorFlow中的图模式执行方式实现的符号式编程提高了计算性能。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76400457",
   "metadata": {
    "origin_pos": 40
   },
   "source": [
    "### 序列化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfb78f",
   "metadata": {
    "origin_pos": 43,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "编译模型的好处之一是我们可以将模型及其参数序列化（保存）到磁盘。这允许这些训练好的模型部署到其他设备上，并且还能方便地使用其他前端编程语言。同时，通常编译模型的代码执行速度也比命令式编程更快。在TensorFlow中保存模型的底层API是`tf.saved_model`，让我们来看看`saved_model`的运行情况。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a1de90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:38:15.806894Z",
     "iopub.status.busy": "2023-08-18T07:38:15.806292Z",
     "iopub.status.idle": "2023-08-18T07:38:16.512216Z",
     "shell.execute_reply": "2023-08-18T07:38:16.511056Z"
    },
    "origin_pos": 47,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_mlp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 64K\r\n",
      "drwxr-xr-x 2 ci ci   6 Aug 18 07:38 assets\r\n",
      "-rw-r--r-- 1 ci ci 64K Aug 18 07:38 saved_model.pb\r\n",
      "drwxr-xr-x 2 ci ci  66 Aug 18 07:38 variables\r\n"
     ]
    }
   ],
   "source": [
    "net = get_net()\n",
    "tf.saved_model.save(net, 'my_mlp')\n",
    "!ls -lh my_mlp*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e1db76",
   "metadata": {
    "origin_pos": 60
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 命令式编程使得新模型的设计变得容易，因为可以依据控制流编写代码，并拥有相对成熟的Python软件生态。\n",
    "* 符号式编程要求我们先定义并且编译程序，然后再执行程序，其好处是提高了计算性能。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c6fe14",
   "metadata": {
    "origin_pos": 62
   },
   "source": [
    "## 练习\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dd87e",
   "metadata": {
    "origin_pos": 64,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "1. 回顾前几章中感兴趣的模型，能提高它们的计算性能吗？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfffc03",
   "metadata": {
    "origin_pos": 67,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/2787)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}